---
title: 'MAEA: Entrega final'
author: "Alberto Rincón Borreguero"
output:
  pdf_document: default
  html_document:
    df_print: paged
  html_notebook: default
---

```{r setup, include=FALSE}
library(knitr)
if (!require(psych)) install.packages('psych')
  library(psych)
if (!require(MASS)) install.packages('MASS')
library(MASS)
if (!require(asbio)) install.packages('asbio')
library(asbio)
if (!require(WRS2)) install.packages('WRS2')
library(WRS2)
if (!require(DescTools)) install.packages('DescTools')
library(DescTools)
if (!require(plotrix)) install.packages('plotrix')
library(plotrix)
if (!require(onewaytests)) install.packages('onewaytests')
library(onewaytests)
if (!require(fda)) install.packages('fda')
library(fda)
if (!require(quadprog)) install.packages('quadprog')
library(quadprog)

opts_chunk$set(dev = 'pdf', fig.align = 'center')
```


## Problema 1

Se clasificó a 177 personas casadas según su estatus de fumador, variable B, con valores de No Fumador, b1, Poco Fumador, b2, (< 6 cigarrillos/día), Fumador Moderado, b3 ($\geq$ 6 y < 15 cigarrillos/día) y Gran Fumador, b4 ($\geq$ 15 cigarrillos/día), y el de su pareja, variable A, con valores No Fumador, a1, Poco Fumador, a2 ($\geq$ 6 cigarrillos/día), Fumador Moderado, a3 ($\geq$ 6 y < 15 cigarrillos/día) y Gran Fumador, a4 ($\geq$ 15 cigarrillos/día). Los resultados aparecen recogidos en la siguiente tabla:

```{r creacion dataset}
X           <- matrix(c(42,12,18,2,18,22,6,8,4,8,10,12,0,2,6,7), ncol = 4)
colnames(X) <- c("No Fumador","Poco Fumador","Fumador Moderado","Gran Fumador")
rownames(X) <- c("Pareja No fumadora","Pareja Poco Fumadora","Pareja Fumadora Moderada","Pareja Gran Fumadora")
X
``` 
Test de independencia de caracteres $\chi^2$ con hipótesis nula $h_0: Independecia\ entre\ las\ variables\ B\ y\ A.$

```{r chi square, warning=FALSE}
chi2 = chisq.test(X)
chi2
```
Dado que el p-valor es prácticamente cero, `r sprintf("%.10f",chi2$p.value)`, se rechaza la hipótesis nula de independecia entre ambas variables.

Se procede a realizar un análisis de correspondencias para comprobar si exista alguna relación entre los valores observados de las dos variables.

```{r fig.align='center'}
library(ca)
correspondencias <- ca(X)
plot(correspondencias)
```
El gráfico bi-dimensional obtenido establece que las personas entrevistadas que se declararon No Fumadoras o Poco Fumadoras tienen parejas con el mismo hábito. Por otra parte, cuando el entrevistado se declara como Fumador Moderado o Gran Fumador, su pareja, por lo general, es Gran Fumadora. Se aprecia que la observación de la variable A, Pareja Fumadora Moderada, no tiene una relación estrecha con ninguna observacion de la variable B, siendo Poco Fumador la más alejada de todas.

## Problema 2

```{r carga de datos}
injerto <- read.csv("datos/examen/injerto.txt", sep=" ")
head(injerto)
```
**(a)** Dado que las covariables a considerar en un modelo de regresión deben ser independientes, contrastar mediante un test de Spearman de independencia, si pueden considerarse independientes las covariables rcpage y donage.

```{r Spearman, warning=FALSE}
corr <- cor.test(injerto$rcpage, injerto$donage, method = 'spearman')
corr
```
El test de spearman se interpreta de la siguiente forma: Magnitudes de rho cercanas a 1 indican mayor correlación mientras que los valores cercanos a cero indican una menor correlación.
En este caso, el valor **0.72** indica que las variables rcpage y donage **no son independientes**.

**(b)** Analizar mediante una Regresión Logística qué variables son significativas para predecir la probabilidad p de presentar la enfermedad de Injerto contra Huésped, variable gvhd, de entre las 3 covariables siguientes: index, donage, preg.

```{r}
regression <- glm(gvhd~index+donage+preg, data = injerto, family = binomial(link = "logit"))
summary(regression)
```
Se observa que la variable $index$ con p-valor de $0.01$ es la más significativa en la predicción.

**(c)** Determinar la estimación de p en función de las variables que resulten significativas.

```{r}
regression <- glm(formula = gvhd ~ index, family = binomial(link = "logit"), data = injerto)
summary(regression)
```
**(d)** ¿Qué probabilidad de presentar la Enfermedad de injerto contra huésped tiene un individuo con índice reacciones de linfocitos igual a $2'5$, cuyo donante que nunca ha estado embarazada y tiene una edad de 55 años?

```{r eval=TRUE}
probability <- predict.glm(object = regression, data.frame(index=2.5, preg=0 ,donage=55), type = "response")
```

La probabilidad de presentar la enfermedad es del **`r sprintf("%.2f",probability*100)`% **

## Problema 3

Se desea realizar una Regresiónn no Lineal ajustando una función tipo sigmoide a los siguientes pares de datos,

| x  | y  |
|:--:|:--:|
| 19 | 65 |
| 25 | 61 |
| 38 | 56 |
| 47 | 28 |
| 53 | 12 |
| 69 | 10 |

utilizando la correspondiente función de autoarranque. Determinar la función sigmoide ajustada.

```{r carga datos problema 3}
pb3.datos <- data.frame(x = c(19,25,38,47,53,69),
                        y = c(65,61,56,28,12,10))
```

```{r representación gráfica}
```



Sea la función sigmoide: $$\eta(x,\theta) = \theta_1 + \frac{\theta_2 - \theta_1 }{1 + e^{\theta_3(x - \theta_4)}} $$


Se realiza la regresión no lineal, con su correspondiente función de arranque SSfpl, en la siguiente linea.

```{r}
model <- nls(y~ SSfpl(-x,b1,b2,b3,b4), data=pb3.datos)
```

Obtenemos información acerca del modelo generado mediante la función summary.
```{r}
summary(model)
```
La suma de los errores residuales es muy pequeña, como se aprecia a continuación. Por tanto podemos decir que el modelo se ajusta adecuadamente a los datos.

```{r}
sum(resid(model))
```

Por último, mostramos el ajuste del modelo (linea azul) para los datos de la columna y del *dataframe*.

```{r}
plot(pb3.datos, pch=16)
lines(pb3.datos$x, predict(model), col='blue')
```


```{r echo=FALSE, eval=TRUE}
pbvar <-
function(x,beta=.2){
#   Compute the percentage bend midvariance
#
#   beta is the bending constant for omega sub N.
#
pbvar=0
w<-abs(x-median(x))
w<-sort(w)
m<-floor((1-beta)*length(x)+.5)
omega<-w[m]
if(omega>0){
y<-(x-median(x))/omega
z<-ifelse(y>1,1,y)
z<-ifelse(z<(-1),-1,z)
pbvar<-length(x)*omega^2*sum(z^2)/(length(x[abs(y)<1]))^2
}
pbvar
}
```


## Problema 4

  Se desea estudiar el número de hembras de la mosca tropical americana en una determinada región. Dicha mosca se caracteriza por poner sus huevos en un mosquito, pasando las larvas de la mosca a la piel de la persona cuya sangre ha chupado el mosquito.
  Examinada la región en cuestión en 10 días elegidos al azar, se obtuvo el siguiente número de moscas hembra de la citada especie:
                    2,1,3,5,7,2,1,2,3,2
Se pide:

 a) Determinar la estimación clásica y cuatro estimaciones robustas del número medio de moscas hembra en la región en estudio. ¿Con qué estimación concluiría?
 
```{r problema-4a}

data <- c(2,1,3,5,7,2,1,2,3,2)

# media clasica
mean(data) 

# media alpha-winsorizada
winsor.mean(data, trim = 0.1)
winsor.mean(data, trim = 0.2)

# media alpha-recortada muestral
mean(data, trim = 0.1)
mean(data, trim = 0.2)

# mediana muestral
median(data)

# estimador de huber
huber(data, 1.28)$mu
```
Dada la siguiente distribución de los datos:

```{r}
hist(data, main = 'Distribución del modelo poblacional')
```
Al no ser una distribución normal, se descarta la elección a priori de la estimación clásica que, en caso de normalidad, asegura mínima varianza.

Por tanto, y en base a las recomendaciones de la pagina 76 del libro métodos robustos y de remuestreo, **se elige el estimador huber**.

 b) Determinar también la estimación clásica y cuatro estimaciones robustas de la desviación típica del número de moscas hembra en la citada región. ¿Con qué estimación concluiría?

```{r problema-4b}

# cuasidesivación típica muestral (estimación clásica)
sqrt(var(data))

# Desviación absoluta mediana estandarizada
mad(data)

#Cuasidesviación típica alpha-winsorizada muestral
sqrt(winsor.var(data))

#Raíz de la varianza media biponderada
sqrt(r.bw(data))[[1]]

#Raíz de la varianza media de porcentaje ajustado
sqrt(pbvar(data))

```
De la misma forma que en el apartado anterior, se descarta la elección a priori de la estimación clásica y también se sigue la recomendación del libro para **elegir como estimador la desviación absoluta mediana estandarizada** (NMAD)
 
 
## Problema 5

  Los tiempos, en minutos, que esperaron, hasta que fueron atendidos en un determinado banco, diez clientes elegidos al azar fueron los siguientes: 1'5, 2, 2'5, 3, 1, 5, 5'5, 4'5, 3, 3. Determinar un intervalo de confianza de coeficiente de confianza 0'95, para la media 0'2-recortada del tiempo de espera y otro intervalo, también de coeficiente de confianza 0'95 para el tiempo mediano de espera.
  
```{r problema-5}

data <- c(1.5, 2, 2.5, 3, 1, 5, 5.5, 4.5, 3, 3)
```

Cálculo del intervalo de confianza con coeficiente 0'95 para media 0'2-recortada.
```{r problema-5.1}
trimCi <- MeanCI(data, conf.level = 0.95 , trim=0.2)

plot(density(data), main = "Intervalo de confianza a 0'95 para media 0'2-recortada ") + abline(v=trimCi[1], col='green') + text(trimCi[1], 0, "Media") + abline(v=trimCi[2], col='red') + text(trimCi[2], 0.05, "Cota inferior IC") + abline(v=trimCi[3], col='red') + text(trimCi[3], 0.05, "Cota superior IC")

```
Cálculo del intervalo de confianza con coeficiente 0'95 para el tiempo mediano de espera.

```{r problema-5.2}
medianCI <- MedianCI(data, conf.level = 0.95)

plot(density(data), main = "Intervalo de confianza a 0'95 para mediana ") + abline(v=medianCI[1], col='green') + text(medianCI[1], 0, "Mediana") + abline(v=medianCI[2], col='red') + text(medianCI[2], 0.05, "Cota inferior IC") + abline(v=medianCI[3], col='red') + text(medianCI[3], 0.05, "Cota superior IC")

```

## Problema 6

Se quiere averiguar si, en promedio, existen diferencias significativas entre los precios de dos restaurantes, A y B. Para ello se eligieron al azar 11 días en los que se anotó el precio del menú del día en el restaurante A y otros 11 días en los que se anotó el precio del menú del día en el restaurante B. Los datos obtenidos fueron los siguientes:

A: 1325 1500  995 1250 1290 1900 1500 1100 1250 1150 1900
B: 1100 1400 1000 1300 1300 1700 1250 1200 1150 1200 1700

```{r problema-6}
data_A <- c(1325, 1500, 995, 1250, 1290, 1900, 1500, 1100, 1250, 1150, 1900)
data_B <- c(1100, 1400, 1000, 1300, 1300, 1700, 1250, 1200, 1150, 1200, 1700)

```
¿ Puede afirmarse a partir de dichos datos que existen diferencias significativas entre ambos restaurantes a nivel $\alpha = 0'05$ ?


Si comparamos las distribuciones de las poblaciones muestrales se comprueba que las diferencias, a simple vista, son escasas, haciéndose notar en la cola derecha (precios más altos). De hecho, se podría decir que cada distribución está compuesta por la suma de dos distribuciones: Una para los precios baratos y medios, y otra para los precios altos.
```{r problema-6extra}
plot(density(data_A), main = "Curva de densidades A y B")
par(new=TRUE)
plot(density(data_B), col='blue' ,xaxt='n', yaxt='n', ann=FALSE, main = "Restaurante B ")
```


a) Utilizando las diferencias de medias 0'2-recortadas muestrales 

**Aplicando las medias 0'2-recortadas** dada la hipótesis nula $H_0 : \mu_\alpha,_1 = \mu_\alpha,_2$ y la alternativa $H_1 : \mu_\alpha,_1 \neq \mu_\alpha,_2$.

```{r problema-6a}

trimCi_A <- mean(data_A, trim = 0.2)
trimCi_B <- mean(data_B, trim = 0.2)
YuenTTest(data_A, data_B, tr = 0.2, conf.level = 0.95)
```
**Se acepta $H_0$** ya que el valor 0 pertenece al intervalo calculado $[-130.2806 , 263.1377]$ y el p-valor es $0.47$, confirmándose por tanto que **no existen diferencias significativas**.


```{r problema-6a1}

trimCiA <- MeanCI(data_A, conf.level = 0.95 , trim=0.2)
trimCiB <- MeanCI(data_B, conf.level = 0.95 , trim=0.2)

plot(density(data_A), main = "Intervalo de confianza a 0'95 para media 0'2-recortada ") + abline(v=trimCiA[1], col='green') + text(trimCiA[1], 0, "Media") + abline(v=trimCiA[2], col='red') + text(trimCiA[2], 0.001, "Cota inferior IC") + abline(v=trimCiA[3], col='red') + text(trimCiA[3], 0.001, "Cota superior IC")
par(new=TRUE)
plot(density(data_B), col='blue' ,xaxt='n', yaxt='n', ann=FALSE, main = "Intervalo de confianza a 0'95 para media 0'2-recortada ") + abline(v=trimCiB[1], col='green') + abline(v=trimCiB[2], col='red') + abline(v=trimCiB[3], col='red')

```
b) Utilizando la generalización robusta del test de Wilcoxon-Mann-Whitney

Si consideramos la hipótesis nula $H_0 : M_A = M_B$ y la alternativa $H_1 : M_A \neq  M_B$, y dado que $ H_0 : p = 1/2 $, se va a determinar un intervalo de confainza para p, de coeficiente de confianza $0'95$. En caso de que el valor $1/2$ se incluya en el intervalo calculado, entonces se aceptará la hipótesis nula de igualdad de las poblaciones.

Utilizaremos la función wilcox.test, dónde si asignamos el valor del parámetro paired = FALSE, según la documentación estaremos aplicando el test de la suma de rango de Wilcoxon, equivalente al test de Mann-Whitney.

```{r}
wilcox.test(x = data_A, y = data_B, conf.level = 0.95, conf.int = TRUE, paired = FALSE)
```

Puesto que el valor 0.5 se encuentra dentro del intervalo de confianza y que el p-valor es lo suficientemente grande, confirmamos la hipótesis $H_0 : M_A = M_B$.


## Problema 7

Se quiere averiguar si tres fertilizantes, A, B y C presentan diferencias significativas en cuanto a sus efectos sobre el aumento de la cosecha.

Con este propósito se eligieron al azar 15 parcelas al as que se fertilizó aleatoriamente con cada uno de los fertilizantes en cuestión. Los aumentos de cosecha obtenidos fueron los siguientes:

|Fertilizante|Aumento de cosecha|
|-----------:|------------------|
|     A     :|39  33  39  35  32|
|     B     :|36  40  35  30  29|
|     C     :|33  33  36  26  35|

A la vista de estos datos y recortando $\alpha = 0'1$, ¿ puede inferirse que existen diferencias significativas entre los tres fertilizantes?

La siguiente gráfica muestra la ausencia de normalidad en todas las distribuciones, siendo la de B (línea color rojo) las más cercana a dicha normalidad. En el caso de C (color negro), se puede ver una composición de dos distribuciones, siendo la primera de ellas (a la izquierda) presumiblemente normal.

```{r problema-7prev}
A <- c(39,33,39,35,32)
B <- c(36,40,35,30,29)
C <- c(33,33,36,26,35)


plot(density(A), col='BLUE', main='Densidades muestrales de A,B y C')
par(new=TRUE)
plot(density(B), col='RED',xaxt='n', yaxt='n', ann=FALSE)
par(new=TRUE)
plot(density(C), xaxt='n', yaxt='n', ann=FALSE)
```



a) Utilizando la generalización robusta del test de Welch.

```{r problema-7}
clnames <- list("aumentoCosecha", "fertilizante")
A <- data.frame(c(39,33,39,35,32),factor("A"))
names(A) <- clnames 
B <- data.frame(c(36,40,35,30,29), factor("B"))
names(B) <- clnames 
C <- data.frame(c(33,33,36,26,35), factor("C"))
names(C) <- clnames 

x <- rbind(A,B,C)
welch.test(formula =  aumentoCosecha ~ fertilizante, data = x, rate = 0.1)

```


b) Utilizando la generalización robusta del test de Box.

Como vemos a continuación, se reafirma que la diferencia no es estadísticamente significativa.

```{r}
box.test(formula =  aumentoCosecha ~ fertilizante, data = x, verbose = TRUE)
```


## Problema 8

Se cree que la duración del revestimiento de un estanque depende de la cantidad de cal hidráulica que contiene. Para analizar esta relación se midió, en siete revestimientos, el tiempo, Y, hasta la aparición de filtraciones, teniendo cada uno de los revestimientos diferentes porcentajes de cal hidráulica, X. Los resultados obtenidos fueron los siguientes:

X:  4, 10,  80,  45,  25,  60,  90
Y: 12, 26, 180, 132, 100, 200, 230

```{r problema-8prev}
X <- c(4, 10,  80,  45,  25,  60,  90)
Y <- c(12, 26, 180, 132, 100, 200, 230)

```


Se pide:

a) La recta de M-regresión óptima.

```{r problema-8}
plot(X,Y)
```

Se aprecia en la gráfica anterior que no hay ningún punto que pudiera ser considerado outlier.

```{r problema-8a}
mregresion <- rlm(formula = Y~X, method = 'M', scale.est = 'Huber')$coefficients
mregresion
```
Se obtiene que la recta es $ y = 17'39 + 2'41x$ la de mínimos cuadrados, la cual se obtiene ejecutando:

```{r problema-8a2}
ols <- lm(Y~X)$coefficients
ols
```


b) La recta de regresión media biponderada.

También puede obtener mediante la función rlm utilizando 'MM' como método.

```{r problema-8b}
biweighted <- rlm(formula = Y~X, method = 'MM')$coefficients
biweighted
```


c) La recta de regresión winsorizada.

```{r problema-8c}
data <- data.frame(X, Y)

winsr <- lmWinsor(formula = Y~X, data=data)$coefficients
winsr
```

A continuación se dibujan todas las rectas obtenidas en una misma gráfica para su comparación. En dicha gráfica veremos como el resultado obtenido es prácticamente el mismo debido a la ausencia de valores extremos.

```{r problema-8extra}
plot(X,Y)
abline(mregresion)
abline(ols, col=2)
abline(biweighted, col=3)
abline(winsr, col=4)
```


